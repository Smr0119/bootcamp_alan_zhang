{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 13 Homework Starter â€” Productization\n",
    "\n",
    "## Objective\n",
    "Deploy your trained model as a **reusable, handoff-ready API or dashboard** and finalize your project for reproducibility and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Create a mock, very basic analysis in a notebook.\n",
    "2. Clean your notebook by removing exploratory cells and documenting your code.\n",
    "3. Move reusable functions into `/src/`.\n",
    "4. Load your trained model from Stage 12 or earlier stages.\n",
    "5. Pickle/save the model and test reload.\n",
    "6. Implement **either**:\n",
    "   - Flask API with `/predict` endpoint and optional parameters\n",
    "   - Streamlit or Dash dashboard for user interaction\n",
    "7. Include:\n",
    "   - Error handling for invalid inputs\n",
    "   - `requirements.txt` for reproducibility\n",
    "   - Documentation in `README.md`\n",
    "8. Test your deployment locally and provide evidence.\n",
    "9. Organize project folders and finalize notebooks for handoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create mock, very basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = X[:, 0] + 2 * X[:, 1] + np.random.randn(100) * 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"Basic analysis complete.\")\n",
    "print(f\"Model score: {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Notebook Cleanup\n",
    "Remove exploratory cells and document your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook cleaned and ready for handoff.\")\n",
    "print(\"All exploratory code removed, only final analysis remains.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Move reusable functions to /src/\n",
    "Create src/utils.py and store functions there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('src', exist_ok=True)\n",
    "\n",
    "utils_code = '''import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    return df.describe()\n",
    "\n",
    "def preprocess_data(X):\n",
    "    return X\n",
    "\n",
    "def validate_input(features):\n",
    "    if not isinstance(features, list) or len(features) != 2:\n",
    "        return False\n",
    "    return all(isinstance(x, (int, float)) for x in features)\n",
    "'''\n",
    "\n",
    "with open('src/utils.py', 'w') as f:\n",
    "    f.write(utils_code)\n",
    "\n",
    "print(\"Functions moved to src/utils.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Folder Structure Reminder\n",
    "\n",
    "Ensure your project uses a clean folder structure:\n",
    "```\n",
    "project/\n",
    "  data/\n",
    "  notebooks/\n",
    "  src/\n",
    "  reports/\n",
    "  model/\n",
    "  README.md\n",
    "```\n",
    "\n",
    "For API/Dashboard: minimal example:\n",
    "```\n",
    "project/\n",
    "    app.py\n",
    "    model.pkl\n",
    "    requirements.txt\n",
    "    README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pickle / Save Final Model\n",
    "\n",
    "### Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "with open('model/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('model/model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "test_features = [[0.1, 0.2]]\n",
    "prediction = loaded_model.predict(test_features)\n",
    "print(f\"Test prediction: {prediction[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Flask API Starter\n",
    "\n",
    "### Implement Flask endpoints for /predict and /plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open('model/model.pkl', 'rb') as f:\n",
    "    api_model = pickle.load(f)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        features = data.get('features', None)\n",
    "        if features is None or len(features) != 2:\n",
    "            return jsonify({'error': 'Need exactly 2 features'}), 400\n",
    "        pred = float(api_model.predict([features])[0])\n",
    "        return jsonify({'prediction': pred})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "@app.route('/predict/<float:input1>', methods=['GET'])\n",
    "def predict_one(input1):\n",
    "    try:\n",
    "        pred = float(api_model.predict([[input1, 0]])[0])\n",
    "        return jsonify({'prediction': pred})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "@app.route('/predict/<float:input1>/<float:input2>', methods=['GET'])\n",
    "def predict_two(input1, input2):\n",
    "    try:\n",
    "        pred = float(api_model.predict([[input1, input2]])[0])\n",
    "        return jsonify({'prediction': pred})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "@app.route('/plot')\n",
    "def plot():\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    x_vals = np.linspace(-2, 2, 50)\n",
    "    y_vals = api_model.predict([[x, 0] for x in x_vals])\n",
    "    ax.plot(x_vals, y_vals, 'b-', label='Model predictions')\n",
    "    ax.set_xlabel('Input 1')\n",
    "    ax.set_ylabel('Prediction')\n",
    "    ax.legend()\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img_bytes = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    plt.close(fig)\n",
    "    return f'<img src=\"data:image/png;base64,{img_bytes}\"/>'\n",
    "\n",
    "def run_flask():\n",
    "    app.run(port=5000, debug=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask)\n",
    "flask_thread.daemon = True\n",
    "flask_thread.start()\n",
    "time.sleep(2)\n",
    "print(\"Flask API started on port 5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the Flask API from Notebook\n",
    "\n",
    "### Test API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://127.0.0.1:5000/predict',\n",
    "        json={'features': [0.1, 0.2]},\n",
    "        timeout=5\n",
    "    )\n",
    "    print(\"POST /predict:\", response.json())\n",
    "\n",
    "    response2 = requests.get('http://127.0.0.1:5000/predict/2.0', timeout=5)\n",
    "    print(\"GET /predict/2.0:\", response2.json())\n",
    "\n",
    "    response3 = requests.get('http://127.0.0.1:5000/predict/1.0/3.0', timeout=5)\n",
    "    print(\"GET /predict/1.0/3.0:\", response3.json())\n",
    "\n",
    "    response_plot = requests.get('http://127.0.0.1:5000/plot', timeout=5)\n",
    "    if response_plot.status_code == 200:\n",
    "        display(HTML(response_plot.text))\n",
    "        print(\"Plot endpoint working\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"API test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optional Streamlit / Dash Dashboard\n",
    "\n",
    "### Add dashboard in a separate file (`app_streamlit.py` or `app_dash.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_code = '''import streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "st.title(\"Model Prediction Dashboard\")\n",
    "\n",
    "with open(\"model/model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "input1 = st.number_input(\"Feature 1\", value=0.0)\n",
    "input2 = st.number_input(\"Feature 2\", value=0.0)\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    prediction = model.predict([[input1, input2]])[0]\n",
    "    st.write(f\"Prediction: {prediction:.3f}\")\n",
    "'''\n",
    "\n",
    "with open('app_streamlit.py', 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "print(\"Streamlit app created as app_streamlit.py\")\n",
    "print(\"Run with: streamlit run app_streamlit.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Handoff Best Practices\n",
    "\n",
    "- Ensure README.md is complete and clear\n",
    "- Provide `requirements.txt` for reproducibility\n",
    "- Ensure pickled model and scripts are in correct folders\n",
    "- Verify another user can run the project end-to-end on a fresh environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = '''flask==2.3.3\n",
    "scikit-learn==1.3.0\n",
    "pandas==2.0.3\n",
    "numpy==1.24.3\n",
    "matplotlib==3.7.1\n",
    "streamlit==1.25.0\n",
    "requests==2.31.0\n",
    "'''\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "readme = '''# Model API Project\n",
    "\n",
    "## Setup\n",
    "1. Install requirements: `pip install -r requirements.txt`\n",
    "2. Run Flask API: `python -c \"from stage13_productization_homework_starter import *; run_flask()\"`\n",
    "3. Run Streamlit: `streamlit run app_streamlit.py`\n",
    "\n",
    "## API Endpoints\n",
    "- POST /predict: Send JSON with features\n",
    "- GET /predict/<input1>: Single feature prediction\n",
    "- GET /predict/<input1>/<input2>: Two feature prediction\n",
    "- GET /plot: View model plot\n",
    "\n",
    "## Model\n",
    "Simple linear regression model trained on synthetic data.\n",
    "Takes 2 features and predicts continuous output.\n",
    "'''\n",
    "\n",
    "with open('README.md', 'w') as f:\n",
    "    f.write(readme)\n",
    "\n",
    "print(\"Requirements and README created\")\n",
    "print(\"Project ready for handoff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.10" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
